{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e5ee88-1915-4c78-a289-4f0861a42f7d",
   "metadata": {},
   "source": [
    "## Description\n",
    "The objective of this competition is to create a machine learning model to detect fraudulent transactions.\n",
    "\n",
    "Fraud detection is an important application of machine learning in the financial services sector. This solution will help Xente provide improved and safer service to its customers.\n",
    "\n",
    "This competition is sponsored by Xente, Innovation Village, and insight2impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6fbaf-cca6-4eff-a552-1cf359912666",
   "metadata": {},
   "source": [
    "## Data\n",
    "Xente is an e-commerce and financial service app serving 10,000+ customers in Uganda.\n",
    "\n",
    "This dataset includes a sample of approximately 140,000 transactions that occurred between 15 November 2018 and 15 March 2019.\n",
    "\n",
    "One of the challenges of fraud detection problems is that the data is highly imbalanced. \n",
    "\n",
    "Xente_variable_definitions.csv: Definition of the features per transaction\n",
    "Training.csv: Transactions from 15 November 2018 to 13 February 2019, including whether or not each transaction is fraudulent. You will use this file to train your model.\n",
    "Test.csv: Transactions from 13 February 2019 to 14 March 2019, not including whether or not each transaction is fraudulent. You will test your model on this file.\n",
    "sample_submission.csv: is an example of what your submission file should look like. The order of the rows does not matter, but the names of the TransactionId must be correct. The value in FraudResult will be 1 for is a Fraud and 0 for is not a fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49032cef-fe19-4a17-86f9-434387501f55",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "The error metric for this competition is the F1 score, which ranges from 0 (total failure) to 1 (perfect score). Hence, the closer your score is to 1, the better your model.\n",
    "\n",
    "F1 Score: A performance score that combines both precision and recall. It is a harmonic mean of these two variables. Formula is given as: 2*Precision*Recall/(Precision + Recall)\n",
    "\n",
    "Precision: This is an indicator of the number of items correctly identified as positive out of total items identified as positive. Formula is given as: TP/(TP+FP)\n",
    "\n",
    "Recall / Sensitivity / True Positive Rate (TPR): This is an indicator of the number of items correctly identified as positive out of total actual positives. Formula is given as: TP/(TP+FN)\n",
    "\n",
    "Where:\n",
    "\n",
    "TP=True Positive\n",
    "FP=False Positive\n",
    "TN=True Negative\n",
    "FN=False Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38764bb2-f62d-442e-b39d-4e28271a221b",
   "metadata": {},
   "source": [
    "Info from Leaderboard: score to beat: 0,89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648c816-dc0a-4748-b0f4-8b9ba9bed238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75696f30-238b-48f3-b75c-1bf910193b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the variable names\n",
    "variable_meanings = pd.read_csv(\"data/variable meanings.csv\")\n",
    "pd.set_option('max_colwidth', 800)\n",
    "variable_meanings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f2d99f-0968-4617-b22d-21a5dd93b05d",
   "metadata": {},
   "source": [
    "## Results from Pandas Profile\n",
    "1. There is only one `CurrencyCode`, that means there is no additional information provided by this feature ==> Drop CurrencyCode\n",
    "2. There is only one CountryCode, that means there is no additional information provided by this feature ==> Drop CountryCode\n",
    "3. TransactionIDs are all distinct, that means there is no additional information provided ==> Drop TransactionIds\n",
    "4. TransactionStartTime consist of timestamps. For further analysis ==> group them into timeframes (use \"datetime\")\n",
    "5. Amount contains + and - values (due to debit/credit) ==> we need to create a column with debit credit and transform \"amount\" to absolut values\n",
    "6. Extreeeemely imbalanced target value ==> Oversampling? ==> read further information / links auf zindi nutzen\n",
    "7. Definition for column  CustomerID and AccountId seems to be mixed up\n",
    "\n",
    "8. Transform variable amount (log) due to skewness ==> no log function for negative values ==> we won't use this variable in model\n",
    "9. Transform variable value or value (USD) (log) due to skewness => we choose ValueUSD (smaller values)\n",
    "(10.Transform variable Providerid (log) due to skewness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74be5f8-76eb-446a-805d-9013f8307886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_test = pd.read_csv(\"data/test.csv\")\n",
    "data_train = pd.read_csv(\"data/training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3af7f2-491f-4b85-b296-b8fd900d1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6963f1-7d4b-4fe9-b104-36ceca43f867",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data cleaning\n",
    "\n",
    "* Stripped the ID columns from non-integer characters and converted them to integers\n",
    "* Separated TransactionStartTime into transactiontime and transactiondate\n",
    "* Drop redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e94ed-ec2e-44bc-9889-690d1d54780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_letters(string):\n",
    "    return int(string.split('_')[1])\n",
    "    \n",
    "id_columns = [\"TransactionId\",\"BatchId\",\"AccountId\",\"SubscriptionId\",\"CustomerId\",\"ProviderId\",\"ProductId\",\"ChannelId\"]    \n",
    "for i in id_columns:\n",
    "    data_train[i] = data_train[i].apply(lambda x:remove_letters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd10424-c18a-46e9-90cd-a6f612656d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da62bd0-21c6-43ae-9617-3a425a216c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate `TransactionStartTime` into time and date\n",
    "def convert_to_date(date):\n",
    "    # convert field into datetime format\n",
    "    d = datetime.strptime(date,'%Y-%m-%dT%H:%M:%SZ')\n",
    "    # extract date\n",
    "    return d.date()\n",
    "\n",
    "def convert_to_time(date):\n",
    "    d = datetime.strptime(date,'%Y-%m-%dT%H:%M:%SZ')\n",
    "    # extract time\n",
    "    return d.time()\n",
    "\n",
    "# create new columns with seperate information for `TransactionTime` and `TransactionDate`\n",
    "data_train['TransactionTime'] = data_train.TransactionStartTime.apply(lambda x: convert_to_time(x))\n",
    "data_train['TransactionDate'] = data_train.TransactionStartTime.apply(lambda x: convert_to_date(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6d73b-3fe4-4450-95d5-0f149af673be",
   "metadata": {},
   "source": [
    "Consolidate times into seperate blocks:\n",
    "\n",
    "1. 00:00 - 05:59 (night)\n",
    "2. 06:00 - 09:59 (morning)\n",
    "3. 10:00 - 13:59 (midday)\n",
    "4. 14:00 - 17:59 (afternoon)\n",
    "5. 18:00 - 23:59 (evening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c691912-f349-4626-8f8a-6d4e96785c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that time scale is 0-23\n",
    "data_train.TransactionTime.apply(lambda x: x.hour).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133837fd-fc74-4474-8b24-4b5a97eed163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplly day time consolidation\n",
    "def consolidate_time(time):\n",
    "    if time.hour < 6:\n",
    "        return 'night'\n",
    "    elif time.hour < 10:\n",
    "        return 'morning'\n",
    "    elif time.hour < 14:\n",
    "        return 'midday'\n",
    "    elif time.hour < 18:\n",
    "        return 'afternoon'\n",
    "    else:\n",
    "        return 'evening'\n",
    "    \n",
    "data_train['DayTime'] = data_train.TransactionTime.apply(lambda x: consolidate_time(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f7f7de-00b3-46d9-a0ee-a98257755ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract weekdays from `TransactionDate`\n",
    "data_train['TransactionWeekday'] = data_train.TransactionDate.apply(lambda x: x.isoweekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3261250-3e13-4772-ad9f-03fb1c6090c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature to distinguish between Debit (0) and Credit (1)\n",
    "data_train['DebitCredit'] = data_train.Amount.apply(lambda x: 0 if x > 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdaa11f-902a-4122-a062-d75bb6884c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for value in USD (1 UGX = 0.00028 USD (12.01.2022, UTC 12:10))\n",
    "data_train['ValueUSD'] = data_train.Value.apply(lambda x: x * 0.00028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c39f48e-2155-4adf-ad21-1ce52f9dfbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee458e-88ab-4234-9198-ce45778ffed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(date):\n",
    "    # convert field into datetime format\n",
    "    d = datetime.strptime(date,'%Y-%m-%dT%H:%M:%SZ')\n",
    "    # extract date\n",
    "    return d\n",
    "data_train['DT'] = data_train.TransactionStartTime.apply(lambda x: convert_to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8db16-4fa5-4e81-904e-75835350ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def transactions_toDate(df, transaction_id, account_id):\n",
    "    \"\"\"\n",
    "    returns dataframe\n",
    "    \"\"\"\n",
    "    TTD = {'t_id': [], 'a_id': [], 'count': [], 'date': []}\n",
    "    #print(transaction_id, account_id)\n",
    "    for t, a in zip(transaction_id, account_id):\n",
    "        count = 0\n",
    "        #print(a)\n",
    "        target_date = df.query('TransactionId == @t').DT.dt.to_pydatetime()[0]\n",
    "        for idx, row in df.iterrows():\n",
    "            #print(row.DT-target_date)\n",
    "            #print(type(row.DT))\n",
    "            #print(target_date)\n",
    "            if row.DT < target_date:\n",
    "                #print(row.AccountId)\n",
    "                if row.AccountId == a:\n",
    "                    count += 1\n",
    "                    #print(count)\n",
    "            else:\n",
    "                break\n",
    "        TTD['t_id'] += [t]\n",
    "        TTD['a_id'] += [a]\n",
    "        TTD['count'] += [count]\n",
    "        TTD['date'] += [target_date]\n",
    "    return pd.DataFrame.from_dict(TTD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a391e4-4732-4e78-8e39-c0eaa71f49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=data_train[['TransactionId', 'AccountId', 'CustomerId', 'FraudResult', 'TransactionDate', 'TransactionTime']]\\\n",
    "        .query('FraudResult == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447952b0-d853-4243-b033-da75b3b8e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "TTD = transactions_toDate(data_train, temp.TransactionId, temp.AccountId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce6d06-61f6-4cdf-8f15-3dcfd5a87e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6d5e5-b445-423f-8c99-6339517ef81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that do not convey additional meaning\n",
    "#'TransactionId' ==> remove later before modelling\n",
    "cols_to_drop = ['CurrencyCode', 'CountryCode', 'TransactionStartTime']\n",
    "data_train_clean = data_train.drop(columns=cols_to_drop, inplace=False)\n",
    "data_train_clean.to_csv('data/data_train_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf97ab-3244-4fbe-a350-94bebd8d40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c91e4-88b9-42da-865e-5c3874ef7611",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73194234-3c6b-4d98-8926-55f9d241fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.pie(data_train_clean.groupby('DebitCredit').count()[['TransactionId']].reset_index(), values = 'TransactionId', names ='DebitCredit',title='Percentage of Debit and Credit' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3057d879-791f-43de-a1c4-5dfc57d29138",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.stripplot(data=data_train_clean, x=\"PricingStrategy\", y=\"Value\",hue=\"DebitCredit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4b5ad-2ccc-4d42-9bc5-0c4c0bd5f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.stripplot(data=data_train_clean, x=\"ProductCategory\", y=\"Value\",hue=\"DebitCredit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ccf63-c66e-4dd4-8872-32245168e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.stripplot(data=data_train_clean, x=\"ProviderId\", y=\"Value\",hue=\"DebitCredit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e3e4d8-ac37-4c8d-8f4c-3784ebbabacb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8df574-4ea5-4715-87dc-f6ed3876080e",
   "metadata": {},
   "source": [
    "\n",
    "9. Transform variable value or value (USD) (log) due to skewness\n",
    "(10.Transform variable Providerid (log) due to skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa2fbf-228d-4bde-860a-cb5585734ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_clean['ValueUSDLog']=np.log(data_train_clean.ValueUSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60465df3-6b29-49aa-8771-49976a8225a9",
   "metadata": {},
   "source": [
    "### Dataframe for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7339b-55ea-4b77-bbf7-bfd6e313d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c2a8f-3077-410d-b3a8-8a1613a29af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant = ['Value', 'Amount', 'TransactionId','DT','TransactionTime','TransactionDate','ValueUSD']\n",
    "df = data_train_clean.drop(redundant, axis =1)\n",
    "df.to_csv('data/data_temp.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa949648-f7fa-4840-98ff-2c00b0370702",
   "metadata": {},
   "outputs": [],
   "source": [
    "prov id, prod id, prod cat, channelid, pricing strategie, daytime, weekday, debitcredit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
